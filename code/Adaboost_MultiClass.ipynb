{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f728388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2020/12/implementing-adaboost-algorithm-from-scratch.html\n",
    "#https://github.com/jinxin0924/multi-adaboost/blob/master/multi_AdaBoost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93940bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import choice\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef885cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37eb9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "1     49   F           NAP        160          180          0     Normal   \n",
       "2     37   M           ATA        130          283          0         ST   \n",
       "3     48   F           ASY        138          214          0     Normal   \n",
       "4     54   M           NAP        150          195          0     Normal   \n",
       "..   ...  ..           ...        ...          ...        ...        ...   \n",
       "913   45   M            TA        110          264          0     Normal   \n",
       "914   68   M           ASY        144          193          1     Normal   \n",
       "915   57   M           ASY        130          131          0     Normal   \n",
       "916   57   F           ATA        130          236          0        LVH   \n",
       "917   38   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f29aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='HeartDisease', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQNklEQVR4nO3de7BdZXnH8e8PAuINAUkpJtQwBbVMq+CcoVSKpaIW8BLqhYpVAjKTOkO91NpKazu1trbYaaWgrZ1UkGAVRK1AHadKA1ZtRQi3yEXHlJEhKZDITbxgJ/j0j/3mZRNO4ARZZx9yvp+ZPWe9z7v2Ok8yZ87vrMteK1WFJEkAO0y6AUnS3GEoSJI6Q0GS1BkKkqTOUJAkdQsm3cBPY88996wlS5ZMug1Jely58sorv1tVC6ebe1yHwpIlS1i9evWk25Ckx5UkN29tzsNHkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpG7QTzQn+Q5wL3A/sKmqppLsAXwSWAJ8Bzi2qu5KEuB04Gjgh8AJVXXVkP1Jc9nat71+0i1oDtrv9E8Muv3Z2FP49ao6sKqm2vgUYFVV7Q+samOAo4D922s58OFZ6E2SNGYSh4+WAivb8krgmLH6OTVyGbBbkr0n0J8kzVtDh0IBX0xyZZLlrbZXVd3alm8D9mrLi4Bbxt67rtUeJMnyJKuTrN64ceNQfUvSvDT0XVJ/tarWJ/kZ4OIk3xyfrKpKUtuywapaAawAmJqa2qb3SpIe3qB7ClW1vn3dAHwWOBi4ffNhofZ1Q1t9PbDP2NsXt5okaZYMFgpJnpzkqZuXgZcC1wEXAcvaasuAC9vyRcDxGTkEuGfsMJMkaRYMefhoL+CzoytNWQB8oqr+PckVwPlJTgJuBo5t63+e0eWoaxldknrigL1JkqYxWChU1U3A86ap3wEcMU29gJOH6keS9Mj8RLMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkbsGkG5i0U37xuEm3oDno1OvOnXQL0kQMvqeQZMckVyf5XBvvm+TrSdYm+WSSnVv9CW28ts0vGbo3SdKDzcbho7cBN46N3w+cVlX7AXcBJ7X6ScBdrX5aW0+SNIsGDYUki4GXAR9p4wAvAj7dVlkJHNOWl7Yxbf6Itr4kaZYMvafw98AfAj9p46cDd1fVpjZeByxqy4uAWwDa/D1t/QdJsjzJ6iSrN27cOGDrkjT/DBYKSV4ObKiqKx/L7VbViqqaqqqphQsXPpablqR5b8irjw4FXpnkaGAXYFfgdGC3JAva3sBiYH1bfz2wD7AuyQLgacAdA/YnSdrCYHsKVfVHVbW4qpYArwMuqarfBi4FXtNWWwZc2JYvamPa/CVVVUP1J0l6qEl8eO1dwDuSrGV0zuDMVj8TeHqrvwM4ZQK9SdK8NisfXquqLwFfass3AQdPs859wGtnox9J0vS8zYUkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkbrBQSLJLksuTXJvk+iR/3ur7Jvl6krVJPplk51Z/QhuvbfNLhupNkjS9IfcUfgy8qKqeBxwIHJnkEOD9wGlVtR9wF3BSW/8k4K5WP62tJ0maRYOFQo18vw13aq8CXgR8utVXAse05aVtTJs/IkmG6k+S9FCDnlNIsmOSa4ANwMXA/wB3V9Wmtso6YFFbXgTcAtDm7wGePmR/kqQHGzQUqur+qjoQWAwcDDznp91mkuVJVidZvXHjxp92c5KkMbNy9VFV3Q1cCvwKsFuSBW1qMbC+La8H9gFo808D7phmWyuqaqqqphYuXDh065I0r8woFJKsmklti/mFSXZry08EXgLcyCgcXtNWWwZc2JYvamPa/CVVVTPpT5L02FjwcJNJdgGeBOyZZHdg84nfXXngXMDW7A2sTLIjo/A5v6o+l+QG4LwkfwlcDZzZ1j8T+FiStcCdwOsezT9IkvToPWwoAL8DvB14BnAlD4TC94APPdwbq2oNcNA09ZsYnV/Ysn4f8NpH7FiSNJiHDYWqOh04PclbquqDs9STJGlCHmlPAYCq+mCSFwBLxt9TVecM1JckaQJmFApJPgb8PHANcH8rF2AoSNJ2ZEahAEwBB3g1kCRt32b6OYXrgJ8dshFJ0uTNdE9hT+CGJJczutEdAFX1ykG6kiRNxExD4T1DNiFJmhtmevXRfw7diCRp8mZ69dG9jK42AtiZ0W2wf1BVuw7VmCRp9s10T+Gpm5fbMw6WAocM1ZQkaTK2+S6p7eE5FwC/8di3I0mapJkePnrV2HAHRp9buG+QjiRJEzPTq49eMba8CfgOo0NIkqTtyEzPKZw4dCOSpMmb6UN2Fif5bJIN7fWZJIuHbk6SNLtmeqL5o4yejPaM9vq3VpMkbUdmGgoLq+qjVbWpvc4GfECyJG1nZhoKdyR5Q5Id2+sNwB1DNiZJmn0zDYU3AccCtwG3Aq8BThioJ0nShMz0ktT3Asuq6i6AJHsAf8soLCRJ24mZ7ik8d3MgAFTVncBBw7QkSZqUmYbCDkl23zxoewoz3cuQJD1OzPQX+98BX0vyqTZ+LfC+YVqSJE3KTD/RfE6S1cCLWulVVXXDcG1JkiZhxoeAWggYBJK0HdvmW2dLkrZfhoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQNFgpJ9klyaZIbklyf5G2tvkeSi5N8u33dvdWT5Iwka5OsSfL8oXqTJE1vyD2FTcDvV9UBwCHAyUkOAE4BVlXV/sCqNgY4Cti/vZYDHx6wN0nSNAYLhaq6taquasv3AjcCi4ClwMq22krgmLa8FDinRi4Ddkuy91D9SZIealbOKSRZwuhW218H9qqqW9vUbcBebXkRcMvY29a12pbbWp5kdZLVGzduHK5pSZqHBg+FJE8BPgO8vaq+Nz5XVQXUtmyvqlZU1VRVTS1c6GOiJemxNGgoJNmJUSB8vKr+tZVv33xYqH3d0OrrgX3G3r641SRJs2TIq48CnAncWFUfGJu6CFjWlpcBF47Vj29XIR0C3DN2mEmSNAuGfHraocAbgW8kuabV/hg4FTg/yUnAzcCxbe7zwNHAWuCHwIkD9iZJmsZgoVBVXwWylekjplm/gJOH6keS9Mj8RLMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWDhUKSs5JsSHLdWG2PJBcn+Xb7unurJ8kZSdYmWZPk+UP1JUnauiH3FM4Gjtyidgqwqqr2B1a1McBRwP7ttRz48IB9SZK2YrBQqKovA3duUV4KrGzLK4Fjxurn1MhlwG5J9h6qN0nS9Gb7nMJeVXVrW74N2KstLwJuGVtvXas9RJLlSVYnWb1x48bhOpWkeWhiJ5qrqoB6FO9bUVVTVTW1cOHCATqTpPlrtkPh9s2HhdrXDa2+HthnbL3FrSZJmkWzHQoXAcva8jLgwrH68e0qpEOAe8YOM0mSZsmCoTac5FzgcGDPJOuAPwNOBc5PchJwM3BsW/3zwNHAWuCHwIlD9SVJ2rrBQqGqjtvK1BHTrFvAyUP1IkmaGT/RLEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJ3ZwKhSRHJvlWkrVJTpl0P5I038yZUEiyI/APwFHAAcBxSQ6YbFeSNL/MmVAADgbWVtVNVfV/wHnA0gn3JEnzyoJJNzBmEXDL2Hgd8MtbrpRkObC8Db+f5Fuz0Nt8sSfw3Uk3MRe8P+dNugU9mD+bm51x7mOxlWdubWIuhcKMVNUKYMWk+9geJVldVVOT7kPakj+bs2cuHT5aD+wzNl7capKkWTKXQuEKYP8k+ybZGXgdcNGEe5KkeWXOHD6qqk1Jfhf4ArAjcFZVXT/htuYbD8tprvJnc5akqibdgyRpjphLh48kSRNmKEiSOkNB3l5Ec1aSs5JsSHLdpHuZLwyFec7bi2iOOxs4ctJNzCeGgry9iOasqvoycOek+5hPDAVNd3uRRRPqRdKEGQqSpM5QkLcXkdQZCvL2IpI6Q2Geq6pNwObbi9wInO/tRTRXJDkX+Brw7CTrkpw06Z62d97mQpLUuacgSeoMBUlSZyhIkjpDQZLUGQqSpM5Q0HYpyfe3GJ+Q5EOP0baXJHn92PjwJPckubrdbfbLSV4+Nv/mJMc/Ft9bGtqceRyn9HiQZAGwBHg98Imxqa9U1cvbOgcCFyT5UVWtqqp/mvVGpUfJPQXNO0kWJvlMkiva69BWPzjJ19pf/P+d5NmtfkKSi5JcAqwCTgUOS3JNkt/bcvtVdQ3wXkYfCiTJe5K8sy2/NckNSdYkOa/VntyeG3B5+95LW31Jkq8kuaq9XtDqe7e9kWuSXJfksFZ/aev/qiSfSvKUYf8ntT1yT0HbqycmuWZsvAcP3L7jdOC0qvpqkp9j9GnuXwC+CRxWVZuSvBj4K+DV7T3PB55bVXcmORx459ieweHTfP+rgD+Ypn4KsG9V/TjJbq32buCSqnpTq12e5D+ADcBLquq+JPsD5wJTjPZSvlBV72vPw3hSkj2BPwFeXFU/SPIu4B2MwkmaMUNB26sfVdWBmwdJTmD0CxXgxcABSTZP79r+qn4asLL9Ai5gp7HtXVxV23Jf/2ylvgb4eJILgAta7aXAKzfvTQC7AD8H/C/woXY46n7gWW3+CuCsJDsBF1TVNUl+jdFDkv6r/bt2ZnR7CGmbGAqaj3YADqmq+8aL7UT0pVX1m0mWAF8am/7BNn6PgxjdS2pLLwNeCLwCeHeSX2IUIK+uqm9t0c97gNuB57We74PRg2eSvLBt6+wkHwDuYhRcx21jn9KDeE5B89EXgbdsHrS/xGG0p7D5tuEnPMz77wWeurXJJM8F/pTRY07H6zsA+1TVpcC72vd7CqPDV29J+xM/yUFj/dxaVT8B3gjs2OafCdxeVf8MfITRoa3LgEOT7NfWeXKSZyFtI0NB89Fbgal2svcG4M2t/jfAXye5moffi14D3J/k2rETzYdtviSVURi8tapWbfG+HYF/SfIN4GrgjKq6G/gLRoeq1iS5vo0B/hFYluRa4Dk8sLdyOHBt6/O3gNOraiOjIDs3yRpGh46es03/KxLeJVWSNMY9BUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEnd/wNNKvYQmvv5aQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.countplot(x = heart_data['HeartDisease'], data = heart_data, palette='rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset is overall balanced (not noisy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c43ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   40    1              1        140          289          0           1   \n",
       "1   49    0              2        160          180          0           1   \n",
       "2   37    1              1        130          283          0           2   \n",
       "3   48    0              0        138          214          0           1   \n",
       "4   54    1              2        150          195          0           1   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0    172               0      0.0         2             0  \n",
       "1    156               0      1.0         1             1  \n",
       "2     98               0      0.0         2             0  \n",
       "3    108               1      1.5         1             1  \n",
       "4    122               0      0.0         2             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "heart_data['Sex']=le.fit_transform(heart_data['Sex'])\n",
    "heart_data['RestingECG']=le.fit_transform(heart_data['RestingECG'])\n",
    "heart_data['ChestPainType']=le.fit_transform(heart_data['ChestPainType'])\n",
    "heart_data['ExerciseAngina']=le.fit_transform(heart_data['ExerciseAngina'])\n",
    "heart_data['ST_Slope']=le.fit_transform(heart_data['ST_Slope'])\n",
    "\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82e43c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_data.drop('HeartDisease', axis=1)\n",
    "y = heart_data['HeartDisease']\n",
    "\n",
    "y = np.where(y==0,-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa5e0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a binary \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4aa747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------- BINARY CLASSIFICATIONS ---------------------- #\n",
    "\n",
    "class BinaryClassAdaboost():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators:int):\n",
    "        \"\"\"\n",
    "        Initialialisation of Adaboost class\n",
    "        Parameters: \n",
    "            n_estimators: int:  number of weak learners \n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.list_WL = [] #list with model\n",
    "        self.list_alpha = [] #list with weight of model \n",
    "        self.estimator_errors = []\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit model \n",
    "        Parameters: \n",
    "            X: array: data\n",
    "            y: array: vector of class labels where yi E Y= {1,..., k} and k = 2\n",
    "        \"\"\"\n",
    "        ## Step 1: Initialize the weights to a constant\n",
    "        n_samples = X.shape[0]                \n",
    "        w = []\n",
    "        ##Weights are initialized to 1/Number of samples: \n",
    "        w_t = [1/n_samples for x in range(n_samples)]       \n",
    "              \n",
    "        \n",
    "        ## Step 2: Classify with ramdom sampling of data using a weak learner\n",
    "        #Construction des weaklearner\n",
    "        \n",
    "        #for each weak learner\n",
    "        for t in range(self.n_estimators):\n",
    "\n",
    "            #Choose and Call the Base/Weak learner\n",
    "            #A decision tree with one depth has one node and is called a stump or weak learner\n",
    "            WL = DecisionTreeClassifier(max_depth=1)\n",
    "            #Fit the stump model with the ramdom samples\n",
    "            WL.fit(X, y, sample_weight=w_t)\n",
    "            #Get the predicted classes\n",
    "            y_pred = WL.predict(X)\n",
    "            \n",
    "            ##Step 3: Compute error of weak learner\n",
    "            eps = self.error_wl(w_t, y_pred, y)\n",
    "        \n",
    "            # if the error of the weak learner is higher then 0.5 (worse then random guess) \n",
    "            #don't take into account this learner weight\n",
    "            if eps > 0.5:\n",
    "                break\n",
    "            \n",
    "            #Step 4: Calculate the performance of the weak learner\n",
    "            #Performance of the weak learner(α) = 0.5* ln (1 – error/error)\n",
    "            #Calculate alpha for this weak learner\n",
    "            \n",
    "            alpha_t = 0.5 * np.log((1- eps) / eps)\n",
    "\n",
    "            #Step 5: Update weight\n",
    "            #With the alpha performance (α) the weights of the wrongly classified records are increased\n",
    "            #and the weights of the correctly classified records decreased.\n",
    "            y_temp = np.multiply(y, y_pred)\n",
    "            y_temp2 = -alpha_t * y_temp \n",
    "            normalized_w_t = np.multiply(w_t, np.exp(y_temp2))\n",
    "\n",
    "            #normalizing the weigths for the sum to be equal do 1\n",
    "            w_t = normalized_w_t / sum(normalized_w_t)\n",
    "            \n",
    "            #store the alpha performance of each weak learner\n",
    "            self.list_alpha.append(alpha_t)\n",
    "            #store each weak learner\n",
    "            self.list_WL.append(WL)\n",
    "            self.estimator_errors.append(eps)\n",
    "\n",
    "            \n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict output of Adaboost \n",
    "        Paramters: \n",
    "            X: array: data\n",
    "        Return: \n",
    "            y_pred: array: data\n",
    "        \"\"\"\n",
    "        #The final prediction is a compromise between all the weak learners predictions\n",
    "        list_y_pred = []\n",
    "        \n",
    "        #for each weak learner get their prediction\n",
    "\n",
    "        for WL, w in zip(self.list_WL, self.list_alpha):\n",
    "            #Final prediction is obtained by the weighted by alpha sum of each weak learner prediction\n",
    "            list_y_pred.append(WL.predict(X) * w)\n",
    "         \n",
    "        #the array of all the predictions\n",
    "\n",
    "        arr_y_pred = np.array(sum(list_y_pred))\n",
    " \n",
    "        #get -1 if y_pred < 0 or 1 if y_pred > 0\n",
    "        y_pred = np.sign(arr_y_pred)\n",
    "        \n",
    "        return y_pred \n",
    "        \n",
    "    def error_wl(self, w_t, y_pred, y):\n",
    "        \"\"\"\n",
    "        error of current weaklearner\n",
    "        Parameters:\n",
    "            w_t: array:  weight of observation\n",
    "            y_pred: array: output of wl \n",
    "            y: array: labels\n",
    "        Return: \n",
    "            eps: float: error of wl \n",
    "        \"\"\"\n",
    "        \n",
    "        ind_err = []\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if y_pred[i] != y[i]:\n",
    "                ind_err.append(1) \n",
    "            else: \n",
    "                ind_err.append(0) \n",
    "    \n",
    "        w_ind_err = np.multiply(w_t,ind_err)\n",
    "        \n",
    "        eps = np.sum(w_ind_err)\n",
    "    \n",
    "        return eps\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47511ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BinaryClassAdaboost at 0x23d33cb7eb0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BinaryClassAdaboost(50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6922ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------- BINARY CLASSIFICATIONS ---------------------- #\n",
    "\n",
    "class BinaryClassAdaboostSampling():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators:int):\n",
    "        \"\"\"\n",
    "        Initialialisation of Adaboost class\n",
    "        Parameters: \n",
    "            n_estimators: int:  number of weak learners \n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.list_WL = [] #list with model\n",
    "        self.list_alpha = [] #list with weight of model \n",
    "        self.estimator_errors = []\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit model \n",
    "        Parameters: \n",
    "            X: array: data\n",
    "            y: array: vector of class labels where yi E Y= {1,..., k} and k = 2\n",
    "        \"\"\"\n",
    "        ## Step 1: Initialize the weights to a constant\n",
    "        n_samples = X.shape[0]                \n",
    "        w = []\n",
    "        ##Weights are initialized to 1/Number of samples: \n",
    "        w_t = [1/n_samples for x in range(n_samples)]       \n",
    "              \n",
    "        \n",
    "        ## Step 2: Classify with ramdom sampling of data using a weak learner\n",
    "        #Construction des weaklearner\n",
    "        \n",
    "        #for each weak learner\n",
    "        for t in range(self.n_estimators):\n",
    "            \n",
    "            X_sample, y_sample = self.sampling(X, y, w_t)\n",
    "            #Choose and Call the Base/Weak learner\n",
    "            #A decision tree with one depth has one node and is called a stump or weak learner\n",
    "            WL = DecisionTreeClassifier(max_depth=1)\n",
    "            #Fit the stump model with the ramdom samples\n",
    "            WL.fit(X_sample, y_sample)\n",
    "            #Get the predicted classes\n",
    "            y_pred = WL.predict(X)\n",
    "            \n",
    "            ##Step 3: Compute error of weak learner\n",
    "            eps = self.error_wl(w_t, y_pred, y)\n",
    "        \n",
    "            # if the error of the weak learner is higher then 0.5 (worse then random guess) \n",
    "            #don't take into account this learner weight\n",
    "            if eps > 0.5:\n",
    "                break\n",
    "            \n",
    "            #Step 4: Calculate the performance of the weak learner\n",
    "            #Performance of the weak learner(α) = 0.5* ln (1 – error/error)\n",
    "            #Calculate alpha for this weak learner\n",
    "            \n",
    "            alpha_t =  eps/(1- eps)\n",
    "            \n",
    "\n",
    "            #Step 5: Update weight\n",
    "            #With the alpha performance (α) the weights of the wrongly classified records are increased\n",
    "            #and the weights of the correctly classified records decreased.\n",
    "            y_temp = np.multiply(y, y_pred)\n",
    "            y_temp2 = -alpha_t * y_temp \n",
    "            normalized_w_t = np.multiply(w_t, np.exp(y_temp2))\n",
    "\n",
    "            #normalizing the weigths for the sum to be equal do 1\n",
    "            w_t = normalized_w_t / sum(normalized_w_t)\n",
    "            \n",
    "            #store the alpha performance of each weak learner\n",
    "            self.list_alpha.append(alpha_t)\n",
    "            #store each weak learner\n",
    "            self.list_WL.append(WL)\n",
    "            self.estimator_errors.append(eps)\n",
    "\n",
    "            \n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict output of Adaboost \n",
    "        Paramters: \n",
    "            X: array: data\n",
    "        Return: \n",
    "            y_pred: array: data\n",
    "        \"\"\"\n",
    "        #The final prediction is a compromise between all the weak learners predictions\n",
    "        list_y_pred = []\n",
    "        \n",
    "        #for each weak learner get their prediction\n",
    "\n",
    "        for WL, w in zip(self.list_WL, self.list_alpha):\n",
    "            #Final prediction is obtained by the weighted by alpha sum of each weak learner prediction\n",
    "            list_y_pred.append(WL.predict(X) * w)\n",
    "         \n",
    "        #the array of all the predictions\n",
    "\n",
    "        arr_y_pred = np.array(sum(list_y_pred))\n",
    " \n",
    "        #get -1 if y_pred < 0 or 1 if y_pred > 0\n",
    "        y_pred = np.sign(arr_y_pred)\n",
    "        \n",
    "        return y_pred \n",
    "        \n",
    "    def error_wl(self, w_t, y_pred, y):\n",
    "        \"\"\"\n",
    "        error of current weaklearner\n",
    "        Parameters:\n",
    "            w_t: array:  weight of observation\n",
    "            y_pred: array: output of wl \n",
    "            y: array: labels\n",
    "        Return: \n",
    "            eps: float: error of wl \n",
    "        \"\"\"\n",
    "        \n",
    "        ind_err = []\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if y_pred[i] != y[i]:\n",
    "                ind_err.append(1) \n",
    "            else: \n",
    "                ind_err.append(0) \n",
    "    \n",
    "        w_ind_err = np.multiply(w_t,ind_err)\n",
    "        \n",
    "        eps = np.sum(w_ind_err)\n",
    "    \n",
    "        return eps\n",
    "    \n",
    "    def sampling(self, X, y, w_t):\n",
    "            \"\"\"\n",
    "            sampling X with w_t \n",
    "            Parameters:\n",
    "                X: array: data\n",
    "                y: array: labels\n",
    "                w_t: array: weigth\n",
    "            Return:\n",
    "                X_sample: array: sample of X\n",
    "                y_sample: array: labels corresponding to X_sample\n",
    "            \"\"\"\n",
    "            #put X and y in same array to sample \n",
    "            print(y.shape)\n",
    "            print(X.shape)\n",
    "            \n",
    "            y_temp = np.array(y).reshape(y.shape[0],1)\n",
    "            data = np.hstack((X, y_temp))\n",
    "            #size of sample\n",
    "            size = int(0.75*X.shape[0])\n",
    "            #print(w_t)\n",
    "            \n",
    "            #sample\n",
    "            sample = choice([x for x in range(data.shape[0])], size, w_t)\n",
    "            #ch = choice([x for x in range(data.shape[0])], size, [1 for x in range(data.shape[0])])\n",
    "            sample = data[sample,:]\n",
    "\n",
    "            y_sample = sample[:,-1]\n",
    "            X_sample = sample[:,:-1]        \n",
    "            print(X_sample.shape)\n",
    "            print(y_sample)\n",
    "            return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4c249c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(3000, 10)\n",
      "(2250, 10)\n",
      "[2. 1. 2. ... 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BinaryClassAdaboostSampling at 0x23d33c79310>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BinaryClassAdaboostSampling(50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6dc5764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31c843a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be2ea530",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5db82e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8396739130434783"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3af64f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------Multiclass LASSIFICATIONS ---------------------- #\n",
    "\n",
    "\n",
    "class MultiClassAdaBoost(object):\n",
    "    '''\n",
    "    Parameters\n",
    "    -----------\n",
    "    base_estimator: object\n",
    "        The base model from which the boosted ensemble is built.\n",
    "    n_estimators: integer, optional(default=50)\n",
    "        The maximum number of estimators\n",
    "    learning_rate: float, optional(default=1)\n",
    "    Attributes\n",
    "    -------------\n",
    "    estimators_: list of base estimators\n",
    "    estimator_weights_: array of floats\n",
    "        Weights for each base_estimator\n",
    "    estimator_errors_: array of floats\n",
    "        Classification error for each estimator in the boosted ensemble.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_estimators, learning_rate):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.list_WL = [] #list with model\n",
    "        self.list_alpha = [] #list with weight of model \n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.estimator_errors = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        ## Step 1: Initialize the weights to a constant\n",
    "        n_samples = X.shape[0]                \n",
    "        w = []\n",
    "        ##Weights are initialized to 1/Number of samples: \n",
    "        w_t = [1/n_samples for x in range(n_samples)]       \n",
    "        \n",
    "        # So in boost we have to ensure that the predict results have the same classes sort\n",
    "        self.classes_ = np.array(sorted(list(set(y))))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        \n",
    "        \n",
    "        ## Step 2: Classify with ramdom sampling of data using a weak learner\n",
    "        #Construction des weaklearner\n",
    "        \n",
    "        #for each weak learner\n",
    "        for t in range(self.n_estimators):\n",
    "          \n",
    "            #Choose and Call the Base/Weak learner\n",
    "            #A decision tree with one depth has one node and is called a stump or weak learner\n",
    "            WL = DecisionTreeClassifier(max_depth=1)\n",
    "            #Fit the stump model with the ramdom samples\n",
    "            WL.fit(X, y, sample_weight=w_t)\n",
    "            \n",
    "            y_pred = WL.predict(X)\n",
    "            \n",
    "            ##Step 3: Compute error of weak learner\n",
    "            incorrect = y_pred != y\n",
    "            estimator_error = np.dot(incorrect, w_t) / np.sum(w_t, axis=0)\n",
    "            \n",
    "            # if worse than random guess, stop boosting\n",
    "            #if estimator_error >= 1 - 1 / self.n_classes_:\n",
    "            if estimator_error >0.5:\n",
    "                break\n",
    "\n",
    "            # update alphe performance\n",
    "            alpha_t = self.learning_rate_ * np.log((1 - estimator_error) / estimator_error) + np.log(\n",
    "            self.n_classes_ - 1)\n",
    "        \n",
    "\n",
    "            # update sample weight\n",
    "            w_t *= np.exp(alpha_t * incorrect)\n",
    "            sample_weight_sum = np.sum(w_t, axis=0)\n",
    "\n",
    "            # normalize sample weight\n",
    "            w_t /= sample_weight_sum\n",
    "            \n",
    "            #store the alpha performance of each weak learner\n",
    "            self.list_alpha.append(alpha_t)\n",
    "            #store each weak learner\n",
    "            self.list_WL.append(WL)\n",
    "            # append error\n",
    "            self.estimator_errors.append(estimator_error)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_classes = self.n_classes_\n",
    "        classes = self.classes_[:, np.newaxis]\n",
    "\n",
    "        \n",
    "        pred = sum((estimator.predict(X) == classes).T * w\n",
    "                   for estimator, w in zip(self.list_WL,\n",
    "                                           self.list_alpha))\n",
    "\n",
    "        pred /= sum(self.list_alpha)\n",
    "        if n_classes == 2:\n",
    "            pred[:, 0] *= -1\n",
    "            pred = pred.sum(axis=1)\n",
    "            return self.classes_.take(pred > 0, axis=0)\n",
    "\n",
    "        return self.classes_.take(np.argmax(pred, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2804224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_gaussian_quantiles(\n",
    "    n_samples=13000, n_features=10, n_classes=3, random_state=1\n",
    ")\n",
    "\n",
    "n_split = 3000\n",
    "\n",
    "X_train, X_test = X[:n_split], X[n_split:]\n",
    "y_train, y_test = y[:n_split], y[n_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dedf91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiClassAdaBoost(50, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17ae1608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiClassAdaBoost at 0x23d33cb2640>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc57dbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1890909090909091,\n",
       " 0.18931425566189644,\n",
       " 0.18953758073001337,\n",
       " 0.18976088395042062,\n",
       " 0.18998416497888615,\n",
       " 0.19020742347178698,\n",
       " 0.19043065908610937,\n",
       " 0.19065387147944998,\n",
       " 0.19087706031001675,\n",
       " 0.19110022523663023,\n",
       " 0.19132336591872362,\n",
       " 0.19154648201634444,\n",
       " 0.19176957319015486,\n",
       " 0.191992639101433,\n",
       " 0.1922156794120734,\n",
       " 0.19243869378458822,\n",
       " 0.1926616818821079,\n",
       " 0.19288464336838188,\n",
       " 0.19310757790777966,\n",
       " 0.1933304851652915,\n",
       " 0.1935533648065291,\n",
       " 0.1937762164977267,\n",
       " 0.19399903990574166,\n",
       " 0.1942218346980552,\n",
       " 0.19444460054277318,\n",
       " 0.1946673371086273,\n",
       " 0.19489004406497518,\n",
       " 0.19511272108180125,\n",
       " 0.19533536782971805,\n",
       " 0.1955579839799664,\n",
       " 0.1957805692044163,\n",
       " 0.19600312317556762,\n",
       " 0.19622564556655078,\n",
       " 0.19644813605112754,\n",
       " 0.1966705943036916,\n",
       " 0.19689301999926936,\n",
       " 0.19711541281352052,\n",
       " 0.19733777242273878,\n",
       " 0.19756009850385237,\n",
       " 0.197782390734425,\n",
       " 0.19800464879265617,\n",
       " 0.19822687235738207,\n",
       " 0.198449061108076,\n",
       " 0.1986712147248491,\n",
       " 0.19889333288845085,\n",
       " 0.19911541528026988,\n",
       " 0.19933746158233426,\n",
       " 0.19955947147731232,\n",
       " 0.1997814446485131,\n",
       " 0.2000033807798871]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96fcb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "699cffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8179347826086957"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79853970",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Weak Learner (use different weak learners or with different parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae94c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore Number of Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff054159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lfurtado\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>Adaboost Classifier</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.829945</td>\n",
       "      <td>0.827771</td>\n",
       "      <td>0.784161</td>\n",
       "      <td>0.848423</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>0.850597</td>\n",
       "      <td>Adaboost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.840108</td>\n",
       "      <td>0.837959</td>\n",
       "      <td>0.791158</td>\n",
       "      <td>0.857795</td>\n",
       "      <td>0.864803</td>\n",
       "      <td>0.858185</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.829945</td>\n",
       "      <td>0.827771</td>\n",
       "      <td>0.784161</td>\n",
       "      <td>0.848423</td>\n",
       "      <td>0.845210</td>\n",
       "      <td>0.850597</td>\n",
       "      <td>Adaboost Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.828866</td>\n",
       "      <td>0.826751</td>\n",
       "      <td>0.783872</td>\n",
       "      <td>0.847470</td>\n",
       "      <td>0.842490</td>\n",
       "      <td>0.849575</td>\n",
       "      <td>Adaboost Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Support Vector Classifier  Decision Tree  \\\n",
       "Accuracy              0.829945                   0.827771       0.784161   \n",
       "Precision             0.840108                   0.837959       0.791158   \n",
       "Recall                0.829945                   0.827771       0.784161   \n",
       "F1 Score              0.828866                   0.826751       0.783872   \n",
       "\n",
       "           Random Forest  Gaussian Naive Bayes  Adaboost Classifier  \\\n",
       "Accuracy        0.848423              0.845210             0.850597   \n",
       "Precision       0.857795              0.864803             0.858185   \n",
       "Recall          0.848423              0.845210             0.850597   \n",
       "F1 Score        0.847470              0.842490             0.849575   \n",
       "\n",
       "                     Best Score  \n",
       "Accuracy    Adaboost Classifier  \n",
       "Precision  Gaussian Naive Bayes  \n",
       "Recall      Adaboost Classifier  \n",
       "F1 Score    Adaboost Classifier  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Comparing with other algo\n",
    "\n",
    "# Define dictionary with performance metrics\n",
    "\n",
    "scores = ['accuracy','precision_weighted','recall_weighted','f1_weighted',]\n",
    "# Instantiate the machine learning classifiers\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "svc_model = LinearSVC(dual=False)\n",
    "dtr_model = DecisionTreeClassifier()\n",
    "rfc_model = RandomForestClassifier()\n",
    "gnb_model = GaussianNB()\n",
    "ada_model = AdaBoostClassifier()\n",
    "#my_ada_model = MultiClassAdaBoost(100, 0.001)\n",
    "\n",
    "\n",
    "# Define the models evaluation function\n",
    "def models_evaluation(X, labels, folds):\n",
    "    \n",
    "    '''\n",
    "    X : data set features\n",
    "    labels : data set target\n",
    "    folds : number of cross-validation folds\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Perform cross-validation to each machine learning classifier\n",
    "    log = cross_validate(log_model, X, labels, cv=folds, scoring=scores)\n",
    "    svc = cross_validate(svc_model, X, labels, cv=folds, scoring=scores)\n",
    "    dtr = cross_validate(dtr_model, X, labels, cv=folds, scoring=scores)\n",
    "    rfc = cross_validate(rfc_model, X, labels, cv=folds, scoring=scores)\n",
    "    gnb = cross_validate(gnb_model, X, labels, cv=folds, scoring=scores)\n",
    "    ada = cross_validate(ada_model, X, labels, cv=folds, scoring=scores)\n",
    "    #my_ada = cross_validate(my_ada_model, X, labels, cv=folds, scoring=scores)\n",
    "\n",
    "    \n",
    "    # Create a data frame with the models perfoamnce metrics scores\n",
    "    models_scores_table = pd.DataFrame({'Logistic Regression':[log['test_accuracy'].mean(),\n",
    "                                                               log['test_precision_weighted'].mean(),\n",
    "                                                               log['test_recall_weighted'].mean(),\n",
    "                                                               log['test_f1_weighted'].mean()],\n",
    "                                       \n",
    "                                      'Support Vector Classifier':[svc['test_accuracy'].mean(),\n",
    "                                                                   svc['test_precision_weighted'].mean(),\n",
    "                                                                   svc['test_recall_weighted'].mean(),\n",
    "                                                                   svc['test_f1_weighted'].mean()],\n",
    "                                       \n",
    "                                      'Decision Tree':[dtr['test_accuracy'].mean(),\n",
    "                                                       dtr['test_precision_weighted'].mean(),\n",
    "                                                       dtr['test_recall_weighted'].mean(),\n",
    "                                                       dtr['test_f1_weighted'].mean()],\n",
    "                                       \n",
    "                                      'Random Forest':[rfc['test_accuracy'].mean(),\n",
    "                                                       rfc['test_precision_weighted'].mean(),\n",
    "                                                       rfc['test_recall_weighted'].mean(),\n",
    "                                                       rfc['test_f1_weighted'].mean()],\n",
    "                                       \n",
    "                                      'Gaussian Naive Bayes':[gnb['test_accuracy'].mean(),\n",
    "                                                              gnb['test_precision_weighted'].mean(),\n",
    "                                                              gnb['test_recall_weighted'].mean(),\n",
    "                                                              gnb['test_f1_weighted'].mean()], \n",
    "                                       \n",
    "                                       \n",
    "                                       'Adaboost Classifier':[ada['test_accuracy'].mean(),\n",
    "                                                              ada['test_precision_weighted'].mean(),\n",
    "                                                              ada['test_recall_weighted'].mean(),\n",
    "                                                              ada['test_f1_weighted'].mean()]\n",
    "                                       },\n",
    "                                      \n",
    "                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "    \n",
    "    # Add 'Best Score' column\n",
    "    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n",
    "    \n",
    "    # Return models performance metrics scores data frame\n",
    "    return(models_scores_table)\n",
    "  \n",
    "# Run models_evaluation function\n",
    "models_evaluation(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cca76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
